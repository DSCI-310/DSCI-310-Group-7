%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]



\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}



        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{Zoo Analysis}
\date{Apr 02, 2022}
\release{}
\author{DSCI310\sphinxhyphen{}group7}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{contents::doc}}


\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\Large Summary}
\end{DUlineblock}

\sphinxAtStartPar
The data set we will be using is Zoo (1990) provided by UC Irvine Machine Learning Repository. It stores data with 7 classes of animals and their related characteristics including animal name, hair, feathers and other attributes. In this project, we will use classification as our method to predict a most likely type of a given animal.

\sphinxAtStartPar
\sphinxstylestrong{Below is a table of contents}
\begin{itemize}
\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{intro::doc}]{\sphinxcrossref{Introduction}}}

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{analysis::doc}]{\sphinxcrossref{Methods \& Results}}}

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{discussion::doc}]{\sphinxcrossref{Discussion}}}

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{references::doc}]{\sphinxcrossref{References}}}

\end{itemize}

\sphinxstepscope


\chapter{Introduction}
\label{\detokenize{intro:introduction}}\label{\detokenize{intro::doc}}
\sphinxAtStartPar
The earth is an amazing planet that cultivates branches of animals. In general, scholars split them into 12 classes including mammals, birds, reptiles, amphibians, fishes, insects, crustaceans, arachnids, echinoderms, worms, mollusks and sponges {[}\hyperlink{cite.references:id2}{BioExplorer.net, 2022}{]}. The traditional way in animal classification is manually identifying the characteristics and attributing it the mostly close class {[}\hyperlink{cite.references:id3}{N. Manohar and Kumar, 2016}{]}. However, it is tedious and time consuming, especially when the data set is very huge. A question hereby comes to us, if we can apply K\sphinxhyphen{}nearest neighbors (KNN) algorithms in predicting the type an animal belongs to given its related characteristics, such as hair, feathers, etc.? Therefore, in this project, we will show how we use KNN to do classification in animals based on data set {[}\hyperlink{cite.references:id5}{Repository, 1990}{]} which contains 1 categorical attribute, 17 Boolean\sphinxhyphen{}valued attributes and 1 numerical attribute. The categorical attribute appears to be the class attribute. Detailed breakdowns are as follows:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{animal name}}: Unique for each instance

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{hair}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{feathers}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{eggs}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{milk}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{airborne}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{aquatic}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{predator}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{toothed}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{backbone}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{breathes}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{venomous}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{fins}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{legs}}: Numeric (set of values: \{0,2,4,5,6,8\})

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{tail}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{domestic}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{catsize}}: Boolean

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{type}}: Numeric (integer values in range {[}1,7{]})

\end{enumerate}

\sphinxstepscope


\chapter{Methods \& Results}
\label{\detokenize{analysis:methods-results}}\label{\detokenize{analysis::doc}}
\sphinxAtStartPar
We are going to use multiple analysis to classify the type of the animals using 16 variables including hair, feathers, eggs, milk, airborne, aquatic, predator, toothed, backbone, breathes, venomous, fins, legs, tail, domestic, catsize as our predictors. To predict the class of a new observation, the algorithms of each type will be further explained before implementation.

\sphinxAtStartPar
The first thing is to import the data. The data set is downloaded from \DUrole{xref,myst}{UCI repository}. It is then saved as a csv file in this project repository. Some exploratory data analysis needs to be run before running the actual analyses on the data set. Here is a preview of pre\sphinxhyphen{}processed data set:

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_remove-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
   index  hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \PYGZbs{}
0      0     1         0     0     1         0        0         1        1   
1      1     1         0     0     1         0        0         0        1   
2      2     0         0     1     0         0        1         1        1   
3      3     1         0     0     1         0        0         1        1   
4      4     1         0     0     1         0        0         1        1   

   backbone  breathes  venomous  fins  legs  tail  domestic  catsize  
0         1         1         0     0     4     0         0        1  
1         1         1         0     0     4     1         0        1  
2         1         0         0     1     0     1         0        0  
3         1         1         0     0     4     0         0        1  
4         1         1         0     0     4     1         0        1  
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
It is checked that there aren’t missing values in the data set, we can clearly deduce that the data set is clean according to the data summary we generated above. Since most features are binary and categorical, there is no need to do normalization and standardization.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=800\sphinxpxdimen]{{fig1}.png}
\caption{A summary table of the data set}\label{\detokenize{analysis:f1}}\end{figure}

\sphinxAtStartPar
As shown in {\hyperref[\detokenize{analysis:f1}]{\sphinxcrossref{\DUrole{std,std-ref}{fig.1}}}}, the histograms of each feature are generated. The ones with skewed distribution might be more decisive in the prediction. However, since the data set is relatively small, all the features except the \sphinxcode{\sphinxupquote{animalName}} are going to be used to predict. In the next part, we are going to split the data, into the training set and testing set. After that, different classification models will be trained and evaluated.


\section{Classification}
\label{\detokenize{analysis:classification}}
\sphinxAtStartPar
Now we will use the training set to build an accurate model, whereas the testing set is used to report the accuracy of the models. Here is a list of algorithms we will use in the following section:
\begin{itemize}
\item {} 
\sphinxAtStartPar
K Nearest Neighbor(KNN)

\item {} 
\sphinxAtStartPar
Decision Tree

\item {} 
\sphinxAtStartPar
Support Vector Machine

\item {} 
\sphinxAtStartPar
Logistic Regression

\end{itemize}

\sphinxAtStartPar
To train and evaluate each model, we split the dataset into training and testing sets. We use 80\% of the total data to train the models, and the rest of the data is aimed to test the models.


\subsection{KNN}
\label{\detokenize{analysis:knn}}
\sphinxAtStartPar
KNN captures the idea of similarity (sometimes called distance, proximity, or closeness)
with some basic mathematics we might have learned earlier. Basically in terms of geometry we can always calculate the distance between points on a graph. Similarly, using KNN we can group similar points together and predict the target with our feature variables(x).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{k_accuracy}.png}
\caption{A plot reveals the relationship between K and corresponding accuracy}\label{\detokenize{analysis:f2}}\end{figure}

\sphinxAtStartPar
As shown in {\hyperref[\detokenize{analysis:f2}]{\sphinxcrossref{\DUrole{std,std-ref}{fig.2}}}}, less K values provide higher accuracy. To find the best K value, we tuned the hyperparameter using GridSearch algorithm. After tuning, the best K value is 1.


\subsection{KNN final model \& Evaluation}
\label{\detokenize{analysis:knn-final-model-evaluation}}
\sphinxAtStartPar
After fitting the model using \sphinxcode{\sphinxupquote{K=1}}, we evaluate the KNN model by Cross Validation and calculating the precision, recall, f1\sphinxhyphen{}score and support.

\sphinxAtStartPar
KNN Cross Validation Result:

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_remove-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
      criteria     score
0     fit\PYGZus{}time  0.003352
1   score\PYGZus{}time  0.000000
2   test\PYGZus{}score  0.936847
3  train\PYGZus{}score  1.000000
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
KNN Classification Report:

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_remove-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
          index  precision  recall  f1\PYGZhy{}score  support
0             1        1.0     1.0       1.0      7.0
1             2        1.0     1.0       1.0      5.0
2             4        1.0     1.0       1.0      1.0
3             5        1.0     1.0       1.0      1.0
4             6        1.0     1.0       1.0      3.0
5             7        1.0     1.0       1.0      4.0
6      accuracy        1.0     1.0       1.0      1.0
7     macro avg        1.0     1.0       1.0     21.0
8  weighted avg        1.0     1.0       1.0     21.0
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\subsection{Decision Tree}
\label{\detokenize{analysis:decision-tree}}
\sphinxAtStartPar
A decision tree is a decision support tool that uses a tree\sphinxhyphen{}like model of decisions and their
possible consequences, including chance event outcomes, resource costs, and utility
The goal of using a Decision Tree is to create a training model that can use to predict
the class or value of the target variable by learning simple decision rules inferred
from prior data(training data).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{dt_accuracy}.png}
\caption{A plot reveals the relationship between deepth and corresponding accuracy}\label{\detokenize{analysis:f3}}\end{figure}

\sphinxAtStartPar
As shown in the {\hyperref[\detokenize{analysis:f3}]{\sphinxcrossref{\DUrole{std,std-ref}{fig.3}}}}, the best depth of the Decision Tree is around small. We can confirm that the best value of the depth is 5 after tuning the hyperparameter and calculating the accuracy.


\subsection{Decision Tree final model \& evaluation}
\label{\detokenize{analysis:decision-tree-final-model-evaluation}}
\sphinxAtStartPar
After training the model, we obtain the Cross Validation score, as well as the precision, recall, f1\sphinxhyphen{}score and support.

\sphinxAtStartPar
DT Cross Validation Result:

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_remove-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
      criteria     score
0     fit\PYGZus{}time  0.001250
1   score\PYGZus{}time  0.000999
2   test\PYGZus{}score  0.950000
3  train\PYGZus{}score  0.995833
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
DT Cross Validation Result:

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_remove-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
          index  precision    recall  f1\PYGZhy{}score    support
0             1   1.000000  1.000000  1.000000   7.000000
1             2   1.000000  1.000000  1.000000   5.000000
2             4   1.000000  1.000000  1.000000   1.000000
3             5   1.000000  1.000000  1.000000   1.000000
4             6   0.750000  1.000000  0.857143   3.000000
5             7   1.000000  0.750000  0.857143   4.000000
6      accuracy   0.952381  0.952381  0.952381   0.952381
7     macro avg   0.958333  0.958333  0.952381  21.000000
8  weighted avg   0.964286  0.952381  0.952381  21.000000
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\subsection{Support Vector Machine}
\label{\detokenize{analysis:support-vector-machine}}
\sphinxAtStartPar
SVM or Support Vector Machine is a linear model for classification and regression problems.
It can solve linear and non\sphinxhyphen{}linear problems and work well for many practical problems.
The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the
data into classes.


\subsection{SVM training model Jaccard Score, final model and evaluation}
\label{\detokenize{analysis:svm-training-model-jaccard-score-final-model-and-evaluation}}
\sphinxAtStartPar
SVM Classification Report:

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_remove-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
          index  precision    recall  f1\PYGZhy{}score    support
0             1   1.000000  1.000000  1.000000   7.000000
1             2   1.000000  1.000000  1.000000   5.000000
2             4   0.333333  1.000000  0.500000   1.000000
3             5   1.000000  1.000000  1.000000   1.000000
4             6   1.000000  1.000000  1.000000   3.000000
5             7   1.000000  0.500000  0.666667   4.000000
6      accuracy   0.904762  0.904762  0.904762   0.904762
7     macro avg   0.888889  0.916667  0.861111  21.000000
8  weighted avg   0.968254  0.904762  0.912698  21.000000
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\subsection{Logistic Regression}
\label{\detokenize{analysis:logistic-regression}}
\sphinxAtStartPar
Logistic Regression is a “Supervised machine learning” algorithm that can be used to model the probability of a certain class or event. It is used when the data is linearly separable and the outcome is binary or dichotomous in nature. That means Logistic regression is usually used for Binary classification problems.


\subsection{Logistic Regression training model Jaccard Score, final model and evaluation}
\label{\detokenize{analysis:logistic-regression-training-model-jaccard-score-final-model-and-evaluation}}
\sphinxAtStartPar
LR Classification Report:

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_remove-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
          index  precision    recall  f1\PYGZhy{}score    support
0             1   0.875000  1.000000  0.933333   7.000000
1             2   0.833333  1.000000  0.909091   5.000000
2             4   0.500000  1.000000  0.666667   1.000000
3             5   0.000000  0.000000  0.000000   1.000000
4             6   0.750000  1.000000  0.857143   3.000000
5             7   1.000000  0.250000  0.400000   4.000000
6      accuracy   0.809524  0.809524  0.809524   0.809524
7     macro avg   0.659722  0.708333  0.627706  21.000000
8  weighted avg   0.811508  0.809524  0.757947  21.000000
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxstepscope


\chapter{Discussion}
\label{\detokenize{discussion:discussion}}\label{\detokenize{discussion::doc}}
\sphinxAtStartPar
After analyzing all the different 4 models K Nearest Neighbor(KNN), Decision Tree, Support Vector Machine and Logistic Regression, we found KNN is best to predict the animal type here. As you have seen in the model evaluation tables before, for accuracy KNN is the best, the second\sphinxhyphen{}best is decision tree method and following by Support Vector Machine and Logistic Regression.

\sphinxAtStartPar
The result of KNN was expected as KNN is the best in grouping similar data points together and giving the best prediction results. Predicting the correct animal type with the highest accuracy have a huge impact on identifying animal types. These models can be used to identify animal types instantly for example if someone saw/discovered an animal and the type is not identified then they can feed all the characteristics fields to the model. The model can predict the animal type accurately, which is way more accurate than identifying and classifying the animal based on common sense. Thus our model can increase the research potential in many fields but not just limited to Marine Science, Animal Science, Forestry, and etc. This might lead to a future question in which how we are going to maintain the accuracy of predictions when working with more diverse groups of animals. Another possible aspect of this can be how some attributes of animals will relate to each other, for instance, relation between animals which has teeth vs predator. Furthermore, how we are going to use those relations to predict behaviors and attributes of newly discovered animals and how we are going to make our perceptions on animals even more detailed. These models and their advancements will not only widen our knowledge in terms of animal biology but will also let us find all other possible relations within the nature in a much more efficient way.

\sphinxstepscope


\chapter{References}
\label{\detokenize{references:references}}\label{\detokenize{references::doc}}
\sphinxAtStartPar


\begin{sphinxthebibliography}{1}
\bibitem[1]{references:id2}
\sphinxAtStartPar
BioExplorer.net. Types of animals. \sphinxstyleemphasis{BioExplorer}, 2022. URL: \sphinxurl{https://www.bioexplorer.net/animals/}.
\bibitem[2]{references:id3}
\sphinxAtStartPar
Y. H. Sharath Kumar N. Manohar and G. H. Kumar. Supervised and unsupervised learning in animal classification. \sphinxstyleemphasis{Communications and Informatics (ICACCI)}, 2016. 2016 International Conference on Advances in Computing.
\bibitem[3]{references:id5}
\sphinxAtStartPar
UCI Machine Learning Repository. Zoo. \sphinxstyleemphasis{UCI Machine Learning Repository}, 1990. URL: \sphinxurl{https://archive.ics.uci.edu/ml/datasets/zoo}.
\end{sphinxthebibliography}







\renewcommand{\indexname}{Index}
\printindex
\end{document}